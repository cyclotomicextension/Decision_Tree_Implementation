{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4bvqz_3Smxy5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeNode:\n",
        "  def __init__(self, data,output):\n",
        "        #split into node at each feature of the data\n",
        "        self.data = data\n",
        "        # children of a node are stored as dicticionary with key\n",
        "        # key is the value upon which each feature is split\n",
        "        self.children = {}\n",
        "        # output represents the class with current majority at this instance of the decision tree\n",
        "        self.output = output\n",
        "        # index will be used to assign a unique index to each node\n",
        "        self.index = -1\n",
        "        \n",
        "  def add_child(self,feature_value,obj):\n",
        "      self.children[feature_value] = obj"
      ],
      "metadata": {
        "id": "FTDIxufMm5hK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "  def __init__(self):\n",
        "    self.root= None\n",
        "\n",
        "#To find the number of \"Yes\" and \"No\", we define unique_count\n",
        "  def unique_count(self, Y):\n",
        "    d={}\n",
        "    for i in Y:\n",
        "      if i in d:\n",
        "        d[i]+=1\n",
        "      else:\n",
        "        d[i]= 1\n",
        "    return d\n",
        "\n",
        "#For every node, given the unique_count, we define entropy or information required.\n",
        "  def entropy(self,Y):\n",
        "    frequency=self.unique_count(Y)\n",
        "    entropy=0\n",
        "    for i in range(frequency):\n",
        "      p=frequency[i]/len(Y)\n",
        "      entropy+=(-p)*np.log2(p)\n",
        "    return entropy\n",
        "\n",
        "#We shall now define the gain ratio, which is ratio of information gain over split information.\n",
        "  def gain_ratio(self, X,Y, selected_feature):\n",
        "    info_ori=self.entropy(Y)\n",
        "    info_f=0 #entropy after splitting upon some particular feature f\n",
        "    split_info=0\n",
        "    values = set(X[:,selected_feature])\n",
        "    #Let us convert X and Y into a dataframe with last column as Y:\n",
        "    df=pd.DataFrame(X)\n",
        "    df[df.shape[1]]=Y\n",
        "    initial_size=df.shape[0]\n",
        "    for i in values:\n",
        "      df1=df[df[selected_feature]==i]\n",
        "      current_size=df1.shape[0]\n",
        "      info_f+=(current_size)/(initial_size)*self.entropy(df1[df1.shape[1]-1])\n",
        "      split_info+=(-(current_size)/(initial_size))*np.log2((current_size)/(initial_size))\n",
        "\n",
        "    if split_info==0:\n",
        "      return np.inf\n",
        "    \n",
        "    info_gain=info_ori-info_f\n",
        "    gain_ratio=info_gain/split_info\n",
        "    return gain_ratio\n",
        "\n",
        "#We will define gini index:\n",
        "  def gini_index(self,Y):\n",
        "#probability of a node i is :\n",
        "    frequency=self.unique_count(Y)\n",
        "    gini_index=1\n",
        "    for i in frequency:\n",
        "      probability=frequency[i]/len(Y)\n",
        "      gini_index-=probability**2\n",
        "    return gini_index\n",
        "\n",
        "#We will now define gini_gain. The higher the value of the gini_gain, the more we decide to go with this feature\n",
        "  def gini_gain(self,X,Y, selected_feature):\n",
        "    gini_ori=self.gini_index(Y)\n",
        "    gini_split_f=0 # defines which split to go with \n",
        "    values = set(X[:,selected_feature])\n",
        "    #Let us convert X and Y into a dataframe with last column as Y:\n",
        "    df=pd.DataFrame(X)\n",
        "    df[df.shape[1]]=Y\n",
        "    initial_size=df.shape[0]\n",
        "    for i in values:\n",
        "      df1=df[df[selected_feature]==i]\n",
        "      current_size=df1.shape[0]\n",
        "      gini_split_f+=(current_size)/(initial_size)*self.gini_index(df1[df1.shape[1]-1])\n",
        "    \n",
        "    gini_gain=gini_ori-gini_split_f\n",
        "    return gini_gain\n",
        "\n",
        "  def DecisionTree(self, X, Y, features, classes, metric, level):\n",
        "    \n",
        "        # If the node has only 1 class\n",
        "        if len(set(Y)) == 1:\n",
        "            print(\"Level\",level)\n",
        "            output = None\n",
        "            for i in classes:\n",
        "                if i in Y:\n",
        "                    output = i\n",
        "                    print(\"Count of\",i,\"=\",len(Y))\n",
        "                else :\n",
        "                    print(\"Count of\",i,\"=\",0)\n",
        "            if metric == \"gain_ratio\":\n",
        "                print(\"Current Entropy is =  0.0\")\n",
        "            elif metric == \"gini_index\":\n",
        "                print(\"Current Gini Index is =  0.0\")\n",
        "\n",
        "            print(\"Reached leaf Node\")\n",
        "            print()\n",
        "            return TreeNode(None,output)\n",
        "\n",
        "        # If we have run out of features to split on then we return max_count\n",
        "        if len(features) == 0:\n",
        "            print(\"Level\",level)\n",
        "            freq_map = self.unique_count(Y)\n",
        "            output = None\n",
        "            max_count = -np.inf\n",
        "            for i in classes:\n",
        "                if i not in freq_map:\n",
        "                    print(\"Count of\",i,\"=\",0)\n",
        "                else :\n",
        "                    if freq_map[i] > max_count :\n",
        "                        output = i\n",
        "                        max_count = freq_map[i]\n",
        "                    print(\"Count of\",i,\"=\",freq_map[i])\n",
        "\n",
        "            if metric == \"gain_ratio\":\n",
        "                print(\"Current Entropy  is =\",self.entropy(Y))\n",
        "            elif metric == \"gini_index\":\n",
        "                print(\"Current Gini Index is =\",self.gini_index(Y))            \n",
        "\n",
        "            print(\"Reached leaf Node\")\n",
        "            print()\n",
        "            return TreeNode(None,output)\n",
        "\n",
        "        \n",
        "        # Finding the best feature to split on\n",
        "        max_gain = -np.inf\n",
        "        final_feature = None\n",
        "        for f in features :\n",
        "            if metric == \"gain_ratio\":\n",
        "                current_gain = self.gain_ratio(X,Y,f)\n",
        "            elif metric ==\"gini_index\":\n",
        "                current_gain = self.gini_gain(X,Y,f)\n",
        "\n",
        "            if current_gain > max_gain:\n",
        "                max_gain = current_gain\n",
        "                final_feature = f\n",
        "\n",
        "        print(\"Level\",level)\n",
        "        freq_map = self.unique_count(Y)\n",
        "        output = None\n",
        "        max_count = -np.inf\n",
        "\n",
        "        for i in classes:\n",
        "            if i not in freq_map:\n",
        "                print(\"Count of\",i,\"=\",0)\n",
        "            else :\n",
        "                if freq_map[i] > max_count :\n",
        "                    output = i\n",
        "                    max_count = freq_map[i]\n",
        "                print(\"Count of\",i,\"=\",freq_map[i])\n",
        "\n",
        "        if metric == \"gain_ratio\" :        \n",
        "            print(\"Current Entropy is =\",self.entropy(Y))\n",
        "            print(\"Splitting on feature  X[\",final_feature,\"] with gain ratio \",max_gain,sep=\"\")\n",
        "            print()\n",
        "        elif metric == \"gini_index\":\n",
        "            print(\"Current Gini Index is =\",self.gini_index(Y))\n",
        "            print(\"Splitting on feature  X[\",final_feature,\"] with gini gain \",max_gain,sep=\"\")\n",
        "            print()\n",
        "\n",
        "            \n",
        "        unique_values = set(X[:,final_feature])\n",
        "        df = pd.DataFrame(X)\n",
        "        df[df.shape[1]] = Y\n",
        "\n",
        "        current_node = TreeNode(final_feature,output)\n",
        "        return current_node"
      ],
      "metadata": {
        "id": "KtuzwRWdnOnf"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}